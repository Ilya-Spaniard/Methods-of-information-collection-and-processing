**Репозиторий содержит выполненные задания к курсу "Методы сбора и обработки данных в сети Интернет". СибГУТИ. 1 курс. Магистратура.**

## Вводное задание (task 0)

Скачайте .txt Льюиса Кэрролла “Алиса в стране чудес”. Очистите текст от пунктуации, наведите статистику по числу вхождения слов в текст, сохраните в виде питоновского словаря. Сортируйте полученные данные по убыванию.

## task1
1. Посмотреть документацию к API GitHub, разобраться как вывести список репозиториев для конкретного пользователя, сохранить JSON-вывод в файле *.json.
2. Возьмите API вконтакте (https://vk.com/dev/first_guide). Сделайте запрос, чтобы получить список всех сообществ на которые вы подписаны.

## task2
Необходимо собрать информацию о вакансиях на вводимую должность с сайтов HH(обязательно) и/или Superjob(по желанию). Приложение должно анализировать несколько страниц сайта. Получившийся список должен содержать в себе минимум:
1.	Наименование вакансии.
2.	Предлагаемую зарплату (разносим в три поля: минимальная и максимальная и валюта. цифры преобразуем к цифрам).
3.	Ссылку на саму вакансию.
4.	Сайт, откуда собрана вакансия. (можно прописать статично hh.ru или superjob.ru)
По желанию можно добавить ещё параметры вакансии (например, работодателя и расположение). Структура должна быть одинаковая для вакансий с обоих сайтов. Общий результат можно вывести с помощью dataFrame через pandas. Сохраните в json либо csv.

## task3

Написать приложение, которое собирает основные новости с сайта на выбор news.mail.ru, lenta.ru, yandex-новости. Для парсинга использовать XPath. Структура данных должна содержать:
 * название источника;
 * наименование новости;
 * ссылку на новость;
 * дата публикации.
 
Сложить собранные новости в БД

## task4

1. Развернуть у себя на компьютере/виртуальной машине/хостинге MongoDB и реализовать функцию, которая будет добавлять только новые вакансии/продукты в вашу базу.
2. Написать функцию, которая производит поиск и выводит на экран вакансии с заработной платой больше введённой суммы (необходимо анализировать оба поля зарплаты). То есть цифра вводится одна, а запрос проверяет оба поля.

## task6

 1) Создать пауков по сбору данных о книгах с сайтов labirint.ru и/или book24.ru
 2) Каждый паук должен собирать:
 
 * Ссылку на книгу;
 * Наименование книги;
 * Автор(ы);
 * Основную цену;
 * Цену со скидкой;
 * Рейтинг книги.
 
3) Собранная информация должна складываться в базу данных

